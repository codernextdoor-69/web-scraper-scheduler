# ğŸ•·ï¸ Automated Web Scraper with Scheduler

This project is a Python-based automated web scraper that periodically scrapes quotes from a demo website and stores them in a local SQLite database. It also provides a CSV export feature for all scraped data via a Flask web interface.

---

## ğŸš€ Features

- Scrapes quotes every 60 seconds using `BeautifulSoup`
- Avoids duplicate entries using a UNIQUE constraint
- Stores data in a lightweight `SQLite` database
- Exports scraped quotes to `scraped_data.csv`
- Simple web interface with download button (powered by Flask)

---

## ğŸ› ï¸ Tech Stack

- **Python 3**
- **Flask** â€“ Web framework
- **BeautifulSoup** â€“ HTML parsing
- **SQLite** â€“ Local database
- **Threading** â€“ Background scraping
- **CSV** â€“ Export functionality

---

## ğŸŒ Live Demo

> ğŸ”— [https://replit.com/@mdshoaibiqbal9/web-scraper-scheduler]

---

## ğŸ“ Project Structure
web-scraper/
â”œâ”€â”€ main.py # Flask web server
â”œâ”€â”€ scraper.py # Scrapes quotes from the website
â”œâ”€â”€ db.py # Initializes DB and inserts data
â”œâ”€â”€ export.py # Exports quotes to CSV
â”œâ”€â”€ scraped_data.db # SQLite database (auto-created)
â”œâ”€â”€ scraped_data.csv # Output CSV file (auto-updated)
â””â”€â”€ requirements.txt # Python dependencies
 2. Install dependencies
 pip install -r requirements.txt
3. Run the project
python3 main.py



